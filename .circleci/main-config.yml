version: 2.1

references:
  tcell_dir: &tcell_dir
               tcell
  # to install a new version of tcell, do  "tar -cvfz tcell-x.y.z.tar.gz tcell" after expanding tcell's zip
  tcell_gcp_path: &tcell_gcp_path
                    gs://ddp-tcell/tcell-1.11.0.tar.gz
  tcell_config_file: &tcell_config_file
                       tcell_agent.config
  ci_support_image: &ci_support_image
                      broadinstitute/study-server-build:2022-06-01A
  root_path: &root_path
               /home/circleci
  repo_path: &repo_path
               /home/circleci/repo
  m2_cache_key: &m2_cache_key
                  pom.xml2-{{ checksum "pom.xml" }}-{{ checksum "pex-antlr/pom.xml" }}-{{ checksum "dss-core/pom.xml" }}-{{ checksum "studybuilder-cli/pom.xml" }}-{{ checksum "dss-server/pom.xml" }}-{{ checksum "housekeeping/pom.xml" }}-{{ checksum "dss-database/pom.xml" }}-{{ checksum "dsm-core/pom.xml" }}-{{ checksum "ddp-common/pom.xml" }}-{{ checksum "dsm-server/pom.xml" }}
  m2_cache_restore_key: &m2_cache_keys
    keys:
      - *m2_cache_key
      - pom.xml2-
  m2_repo_path: &m2_repo_path
                  /home/circleci/.m2/repository
  pepper_apis_path: &pepper_apis_path
                      /home/circleci/repo/pepper-apis
  docs-path: &docs-path
               /home/circleci/repo/pepper-apis/docs
  api-spec-path: &api-spec-path
                   /home/circleci/repo/pepper-apis/docs/specification
  circleci_path: &circleci_path
                   /home/circleci/repo/.circleci
  builds_bucket: &builds_bucket
                   ddp-build-artifacts
  jar_build_bucket_dir: &jar_build_bucket_dir
                          /ddp-study-server-pepper-apis
  housekeeping_test_db: &housekeeping_test_db
                          housekeepingdb
  studyserver_test_db: &studyserver_test_db
                         studyservicedb
  test_parallellism: &test_parallelism 15
  ddp_server_port: &ddp_server_port 5556
  ddp_cache_dir: &ddp_cache_dir #caching test artifacts like Auth0 users
                   /home/circleci/.ddp-cache
  ddp_cache_md5_file: &ddp_cache_md5_file
                        /home/circleci/.ddp-cache-md5.txt

executors:
  test-executor:
    docker:
      - image: broadinstitute/study-server-build:java-2022-06-01A
      # start pubsub emulator
      - image: broadinstitute/study-server-build:pubsub-1
      - image: cimg/redis:5.0
      - image: cimg/mysql:5.7
        environment: &DB_VARS
          MYSQL_ROOT_PASSWORD: rootpw
          MYSQL_DATABASE: test_db
          MYSQL_USER: user
          MYSQL_PASSWORD: passw0rd
      - image: docker.elastic.co/elasticsearch/elasticsearch:7.17.10
        environment:
          # Note: for this test-only container, we do not enable security since it adds an unnecessary
          # layer of complexity
          discovery.type: single-node
          xpack.security.enabled: false
          cluster.name: elasticsearch
          transport.host: localhost
          network.host: 127.0.0.1
          http.port: 9200
    resource_class: medium+ #default medium not big enough for tests

  build-deploy-executor:
    docker: # todo: create new image endpoint, add this in admin tab for faster starts
      - image: *ci_support_image

commands:
  install-tcell:
    parameters:
      tcell_gcp_path:
        type: string
        default: *tcell_gcp_path
    steps:
      - run:
          name: Download tcell files from bucket
          command: |
            TCELL_GCP_PATH='<<parameters.tcell_gcp_path>>'
            vault read -format=json  secret/pepper/prod/v1/conf | jq -r .data.gcp.serviceKey | gcloud auth activate-service-account --key-file=-
            TAR_FILE_URL=`gsutil ls $TCELL_GCP_PATH | sort -r | head -1`

            if [ -z $TAR_FILE_URL ]
            then
              echo "Could not find tcell archive ${TCELL_GCP_PATH}"
              exit 1
            fi
            TAR_FILE_PATH="/tmp/$(basename -- $TAR_FILE_URL)"
            gsutil cp  $TAR_FILE_URL $TAR_FILE_PATH

            # untarring will create a "tcell" dir
            tar --no-same-owner -xvf $TAR_FILE_PATH

  build-jar:
    description: Build jar
    parameters:
      module:
        type: string
      m2_repo:
        type: string
        default: *m2_repo_path
    steps:
      - restore_cache: *m2_cache_keys
      - run:
          name: Run maven install on module << parameters.module >>
          command: |
            mvn install -DskipTests -pl << parameters.module >> -am -Dcheckstyle.skip -Dmaven.repo.local=<< parameters.m2_repo >>

  setup-shared-env:
    description: "Setup shared ENV vars used by multiple scripts"
    steps:
      - run:
          name: Set environment to be used by build
          command: |
            echo "export VAULT_TOKEN=$(vault write -field=token auth/approle/login role_id=$VAULT_ROLE_ID secret_id=$VAULT_ROLE_SECRET_ID)" >> $BASH_ENV
            echo "export SHORT_GIT_SHA=$(echo $CIRCLE_SHA1 | cut -c 1-7)" >> $BASH_ENV
            source $BASH_ENV

  set-deployment-env:
    description: "Determine the deploy target and set the ENVIRONMENT var"
    steps:
      - run:
          name: Determine deployment environment for branch << pipeline.git.branch >>
          command: |
            shopt  -s extglob # We are going to use Bash extended glob patterns
            case "${CIRCLE_BRANCH}" in
            ?(*_)develop)
              DEPLOY_ENV=dev
            ;;
            DDP-?(*))
              DEPLOY_ENV=dev
            ;;
            ?(*_)test)
              DEPLOY_ENV=test
            ;;
            ?(*_)staging)
              DEPLOY_ENV=staging
            ;;
            ?(*_)production)
              DEPLOY_ENV=prod
            ;;
            *)
              echo "Cannot map << pipeline.git.branch >> to a deployment environment"
              exit 17
            ;;
            esac
            echo "Setting deployment ENVIRONMENT to $DEPLOY_ENV"
            echo "export ENVIRONMENT=$DEPLOY_ENV" >> $BASH_ENV
            source $BASH_ENV

  render-configs:
    description: Run api-build.sh for specified application and current development environment
    parameters:
      application:
        type: string
        default: unknown
    steps:
      - run:
          name: show environment variables
          command: env
      - run:
          name: api-build.sh
          command: |
            echo "We are generating api-build.sh for application << parameters.application >> on ${ENVIRONMENT:-dev}"
            ./api-build.sh v1 ${ENVIRONMENT:-dev} . << parameters.application >> --gae-config
          environment: # needed because api-build.sh scripts want to start new docker containers
            USE_DOCKER: false

  create-test-dbs:
    description: Create databases that will be used to run all the tests
    parameters:
      studyserverdb:
        type: string
        default: *studyserver_test_db
      housekeepingdb:
        type: string
        default: *housekeeping_test_db
    steps:
      - wait_for_server:
          port: 3306
          timeout: 15
      - run:
          name: Setup test databases
          command: |
            mysql -h 127.0.0.1 -u root --password=$MYSQL_ROOT_PASSWORD test_db --execute="CREATE DATABASE << parameters.studyserverdb >> CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci"
            mysql -h 127.0.0.1 -u root --password=$MYSQL_ROOT_PASSWORD test_db --execute="CREATE DATABASE << parameters.housekeepingdb >> CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci"
          environment: *DB_VARS

  show-pipeline-vars:
    description: "Show pipeline vars"
    steps:
      - run:
          name: Show pipeline vars
          command: |
            echo "pipeline.id << pipeline.id >>"
            echo "pipeline.number  << pipeline.number  >>"
            echo "pipeline.project.git_url << pipeline.project.git_url >>"
            echo "pipeline.project.type << pipeline.project.type >>"
            echo "pipeline.git.tag << pipeline.git.tag >>"
            echo "pipeline.git.branch << pipeline.git.branch >>"
            echo "pipeline.git.revision << pipeline.git.revision >>"
            echo "pipeline.git.base_revision << pipeline.git.base_revision >>"

  store-jar:
    description: Store jar generated for Java module in a Google bucket.
    parameters:
      module:
        type: string
      jar_base_name:
        type: string
      builds_bucket:
        type: string
        default: *builds_bucket
      jar_build_bucket_dir:
        type: string
        default: *jar_build_bucket_dir
    steps:
      - auth-gcp-service-account:
          env: prod
      - run:
          name: Store jar <<parameters.jar_base_name>>
          command: |
            set -u
            DATE=`date +%F`
            BUILDS_BUCKET='<<parameters.builds_bucket>>'
            JAR_BASE_NAME='<<parameters.jar_base_name>>'
            JAR_BUILD_BUCKET_DIR='<<parameters.jar_build_bucket_dir>>'
            JAR_FILE_NAME="${JAR_BASE_NAME}_${DATE}_${SHORT_GIT_SHA}.jar"
            LOCAL_JAR_FILE_PATH="<< parameters.module >>/target/${JAR_BASE_NAME}.jar"
            JAR_BUCKET_URL="gs://${BUILDS_BUCKET}${JAR_BUILD_BUCKET_DIR}/${JAR_FILE_NAME}"
            gsutil cp "${LOCAL_JAR_FILE_PATH}" "${JAR_BUCKET_URL}"
            echo "${JAR_FILE_NAME} successfully uploaded to ${JAR_BUCKET_URL}"

  retrieve-jar:
    description: Get <<parameters.jar_base_name>> jar from bucket
    parameters:
      jar_base_name:
        type: string
      module:
        type: string
      builds_bucket:
        type: string
        default: *builds_bucket
      jar_build_bucket_dir:
        type: string
        default: *jar_build_bucket_dir
    steps:
      - auth-gcp-service-account:
          env: prod
      - run:
          name: Retrieve <<parameters.jar_base_name>> jar from bucket
          command: |
            set -u
            set +e
            JAVA_MODULE_NAME='<< parameters.module >>'
            BUILDS_BUCKET='<<parameters.builds_bucket>>'
            JAR_BASE_NAME='<<parameters.jar_base_name>>'
            JAR_BUILD_BUCKET_DIR='<<parameters.jar_build_bucket_dir>>'
            JAR_FILE_URL_PATTERN="gs://${BUILDS_BUCKET}${JAR_BUILD_BUCKET_DIR}/${JAR_BASE_NAME}_*_${SHORT_GIT_SHA}.jar"
            echo "Checking for ${JAR_FILE_URL_PATTERN}"
            # For some reason following line generating exit code 1 every time in CircleCI. Use set +e so script can continue
            JAR_FILE_URL=`gsutil ls $JAR_FILE_URL_PATTERN  | sort -r | head -1`
            if [ -z $JAR_FILE_URL ]
              then
                echo "Could not find archive using pattern ${JAR_FILE_URL_PATTERN}"
                exit 1
            fi
            JAR_FILE_PATH="$JAVA_MODULE_NAME/target/${JAR_BASE_NAME}.jar"
            mkdir -p $(dirname $JAR_FILE_PATH)
            gsutil cp  $JAR_FILE_URL $JAR_FILE_PATH
            ls -l $JAR_FILE_PATH
            echo ""

  render-secrets:
    description: Get secret <<parameters.secret_name>> from GCP
    parameters:
      secret_name:
        type: string
      output_file:
        type: string
    steps:
      - run:
          name: Extract secret <<parameters.secret_name>> to file <<parameters.output_file>>
          command: |
            gcloud --project "broad-ddp-${ENVIRONMENT}" secrets versions access latest \
                --secret='<<parameters.secret_name>>' > '<<parameters.output_file>>'
            pwd
            ls -l

  deploy-dsm-jar:
    description: Deploy DSM jar to GCP runtime environment. Note that it assumes DSM jar is found in dsm-server module target directory
    parameters:
      deploy_dir:
        type: string
        default: deployment-assets
      tcell_dir:
        type: string
        default: *tcell_dir
      tcell_config_file:
        type: string
        default: *tcell_config_file
      jar_base_name:
        type: string
        default: DSMServer
      app_config_file:
        type: string
        default: vault.conf
    steps:
      - set-deployment-env
      - auth-gcp-service-account
      - render-secrets:
          secret_name: study-manager-tcell
          output_file: << parameters.tcell_config_file >>
      - render-secrets:
          secret_name: study-manager-config
          output_file: << parameters.app_config_file >>
      - install-tcell
      - run:
          name: gather deployment assets
          command: |
            DEPLOY_DIR='<<parameters.deploy_dir>>'
            TCELL_DIR='<<parameters.tcell_dir>>'
            rm -rf $DEPLOY_DIR
            mkdir -p $DEPLOY_DIR
            cd $DEPLOY_DIR
            cp ../dsm-server/target/<<parameters.jar_base_name>>.jar .
            cp ../<< parameters.app_config_file >> .
            cat ../dsm-server/appengine/StudyManager.tmpl.yaml \
              | sed "s/{{project_id}}/broad-ddp-${ENVIRONMENT}/g" \
              > << parameters.jar_base_name >>.yaml
            cp -r ../$TCELL_DIR .
            cp ../<< parameters.tcell_config_file >> $TCELL_DIR
            pwd
            ls -l
      - deploy-app-to-gae:
          jar_base_name: <<parameters.jar_base_name>>
          deploy_dir: <<parameters.deploy_dir>>

  deploy-jar:
    description: |
      Deploy DSS jar to GCP runtime environment. Note that it assumes DSS jar is found in corresponding Maven module target directory.
    parameters:
      jar_base_name:
        type: string
      module:
        type: string
        default: ''
      application:
        type: string
        default: unknown
      deploy_dir:
        type: string
        default: deployment-assets
      tcell_dir:
        type: string
        default: *tcell_dir
      deploy_config_file_dir:
        type: string
        default: '../src/appengine'
    steps:
      - set-deployment-env
      - render-configs:
          application: <<parameters.application>>
      - install-tcell
      - run:
          name: Gather deployment assets
          command: |
            DEPLOY_DIR='<<parameters.deploy_dir>>'
            TCELL_DIR='<<parameters.tcell_dir>>'
            DEPLOY_CONFIG_FILE_DIR='<<parameters.deploy_config_file_dir>>'
            rm -rf $DEPLOY_DIR
            mkdir -p $DEPLOY_DIR
            cd $DEPLOY_DIR
            cp -r ../$TCELL_DIR .
            cp ../output-config/tcell_agent.config $TCELL_DIR
            cp "../<< parameters.module >>/target/<<parameters.jar_base_name>>.jar" .
            cp "$DEPLOY_CONFIG_FILE_DIR/<<parameters.jar_base_name>>.yaml" .
            cp ../output-config/application.conf .
            cp ../output-config/redisson-jcache.yaml .
            cp ../output-config/redisson-jcache-housekeeping.yaml .
      - deploy-app-to-gae:
          jar_base_name: <<parameters.jar_base_name>>
          deploy_dir: <<parameters.deploy_dir>>

  deploy-app-to-gae:
    parameters:
      jar_base_name:
        type: string
      deploy_dir:
        type: string
    steps:
      - auth-gcp-service-account
      - run:
          name: Deploy <<parameters.jar_base_name>> to GAE
          command: |
            set -u
            pwd
            gcloud app deploy --version="${SHORT_GIT_SHA}" --stop-previous-version --project "broad-ddp-${ENVIRONMENT}" <<parameters.deploy_dir>>/<<parameters.jar_base_name>>.yaml
      - update-deployment-sheet:
          jar_base_name: <<parameters.jar_base_name>>
      - delete-old-service-versions:
          deploy_dir: <<parameters.deploy_dir>>
          deploy_config_base_name: <<parameters.jar_base_name>>

  delete-old-service-versions:
    parameters:
      deploy_dir:
        type: string
      deploy_config_base_name:
        type: string
        default: app
    steps:
      - run:
          name: Delete previous versions of service
          command: |
            set +x
            # extract the service name from the GAE yaml file
            CONFIG_FILE="<<parameters.deploy_dir>>/<<parameters.deploy_config_base_name>>.yaml"
            SERVICE=$(grep -Eo -m1 "^service:\s*.*" "${CONFIG_FILE}" | awk '{print $2}')
            echo "The service name is *${SERVICE}*"

            # find what other versions are currently running
            # skip first line, exclude our version, print 2nd column
            AWK_COMMMAND="NR > 1 && !/${SHORT_GIT_SHA}/ {print \$2}"
            VERSIONS_TO_DELETE=$(gcloud app versions list --service "${SERVICE}" --project "broad-ddp-${ENVIRONMENT}" | awk "${AWK_COMMMAND}")

            # Sometime deleting versions fails. If there are less than 3 versions then we are not going to worry about it
            # and set flag so this job step does not fail when exit error value is generated
            if [[ ! -z $VERSIONS_TO_DELETE ]] && [[ "${#VERSIONS_TO_DELETE[@]}" -lt 3 ]]; then
              set +e
            fi

            for CURRENT_VERSION in $VERSIONS_TO_DELETE; do
              echo "Deleting version $CURRENT_VERSION of service $SERVICE"
              gcloud app versions delete --quiet --service "$SERVICE" "$CURRENT_VERSION" --project "broad-ddp-${ENVIRONMENT}"
            done;
            exit 0

  update-deployment-sheet:
    description: Update our running Google sheet with this deployment
    parameters:
      jar_base_name:
        type: string
    steps:
      - run:
          name: Update deployments sheet
          command: |
            set -u
            set +x
            vault read -format=json secret/pepper/${ENVIRONMENT}/v1/conf  | jq -r .data.gcp.serviceKey |
            /opt/build-utils/reportdeploy.sh "$RELEASE_SHEET_ID" '<<parameters.jar_base_name>> server' "$ENVIRONMENT" "$CIRCLE_BUILD_NUM" "$CIRCLE_BUILD_URL"

  auth-gcp-service-account:
    description: Authenticate service account with credentials stored in vault for specified environment
    parameters:
      env:
        type: string
        default: ''
    steps:
      - run:
          name: Call authenticate with GCP with in deployment environment
          command: |
            PARAM_ENV='<<parameters.env>>'
            TARGET_ENV="${PARAM_ENV:-${ENVIRONMENT}}"
            if [[ -z $TARGET_ENV ]]; then
              echo "Target environment was not set"
              exit 1
            else
              echo "Target vault env: $TARGET_ENV"
              echo "From $PWD"
            fi
            vault read --format=json secret/pepper/${TARGET_ENV}/v1/conf |
              jq -r .data.gcp.serviceKey |
              gcloud auth activate-service-account --key-file=-

  compute-parallel-test-split:
    description: >
      Use CircleCi utility to compute tests to be run in a parallel test job.
      Note that we try to exclude IntegrationTestSuite tests from running in a parallel.
      In current workflow IntegrationTestSuite runs in its own dedicated job.
    parameters:
      circleci_path:
        type: string
        default: *circleci_path
    steps:
      - run:
          name: Split tests
          command: |
            set +x
            set +e
            TEST_DATA_PATH='<< parameters.circleci_path >>/tests'
            mkdir -p "$TEST_DATA_PATH"

            TEST_SRC_DIRECTORY='dss-core/src/test/java'
            TEST_SEARCH_PATTERN='**/*Test.java'

            ALL_TEST_CLASS_NAMES_PATH="${TEST_DATA_PATH}/allTestClassNames.txt"
            SUREFIRE_CLASS_NAMES_PATH="${TEST_DATA_PATH}/surefire_classnames"

            # generate list of tests to be processed
            circleci tests glob "${TEST_SRC_DIRECTORY}/${TEST_SEARCH_PATTERN}" | # fancy circleci 'find' command
              sed -e "s#^${TEST_SRC_DIRECTORY}/\(.*\)\.java#\1#" | # Strip out '.java' and parent directory path
              tr "/" "." >  "$SUREFIRE_CLASS_NAMES_PATH" # Convert to a class name of form org.package.ClassName

            echo "Total number of test class names collected: $(wc -l $SUREFIRE_CLASS_NAMES_PATH)"

            # tests split will figure out which tests to run in this node
            THIS_NODE_TESTS_PATH=/tmp/this_node_tests

            cat $SUREFIRE_CLASS_NAMES_PATH |
              circleci tests split --split-by=timings --timings-type=classname > $THIS_NODE_TESTS_PATH

            echo "Number of test classes circleci wants to execute on this node: $(wc -l < $THIS_NODE_TESTS_PATH)"
            echo "The included test classes are:"
            cat $THIS_NODE_TESTS_PATH

            IGNORE_CLASS_LIST_PATH="${TEST_DATA_PATH}/surefire_classnames_ignore_list"


            # Specify the tests to run by substraction: we tell Surefire what NOT to run
            # Make sure the one CircleCi has calculated are removed from the "ignore" list
            cat $SUREFIRE_CLASS_NAMES_PATH |
              grep -xvf $THIS_NODE_TESTS_PATH > $IGNORE_CLASS_LIST_PATH

            # And ignore the Suite itself
            echo 'org.broadinstitute.ddp.route.IntegrationTestSuite'  >> $IGNORE_CLASS_LIST_PATH

            cp $THIS_NODE_TESTS_PATH "${TEST_DATA_PATH}"

            # save path for next steps
            echo "export IGNORE_CLASS_LIST_PATH=${IGNORE_CLASS_LIST_PATH}" >> $BASH_ENV
            source $BASH_ENV
            echo "Total number of test classes that will be skipped in this node: $(wc -l $IGNORE_CLASS_LIST_PATH)"
      - store_artifacts:
          path: <<parameters.circleci_path>>/tests/

  run-maven-with-pepper-options:
    parameters:
      phase:
        type: string
      pom_file:
        type: string
        default: pom.xml
      module:
        type: string
        default: ''
      additional_options:
        type: string
        default: ''
      config_file_path:
        type: string
        default: output-build-config/testing-inmemorydb.conf
      skip_checkstyle:
        type: boolean
        default: true
      skip_tests:
        type: boolean
        default: true
      m2_repo:
        type: string
        default: *m2_repo_path
      restore_m2_cache:
        type: boolean
        default: false
      save_m2_cache:
        type: boolean
        default: false
      background:
        type: boolean
        default: false
      root_path:
        type: string
        default: *root_path
      ddp_cache_dir:
        type: string
        default: *ddp_cache_dir
      coverage_report:
        type: boolean
        default: false
      sonar_scan:
        type: boolean
        default: false
      sonar_additional_module:
        type: string
        default: ''
    steps:
      - when:
          condition: << parameters.restore_m2_cache >>
          steps:
            - restore_cache: *m2_cache_keys
      - run:
          name: 'Run maven <<parameters.phase>> with options: <<parameters.additional_options>>'
          command: |
            CHECKSTYLE_OPTION=''
            if [[ <<parameters.skip_checkstyle>> = true ]]; then
              CHECKSTYLE_OPTION='-Dcheckstyle.skip'
            fi
            SKIPTESTS_OPTION='-DskipTests=<<parameters.skip_tests>>'
            ddp_cache_dir='<<parameters.ddp_cache_dir>>'
            if [[ ! -d "$ddp_cache_dir" ]]; then
              mkdir -p "$ddp_cache_dir"
            fi

            CONFIG_FILE_OPTION=''
            if [[ ! -z '<< parameters.config_file_path >>' ]]; then
              CONFIG_FILE_PATH=$(readlink -f << parameters.config_file_path >>)
              CONFIG_FILE_OPTION="-Dconfig.file=$CONFIG_FILE_PATH"
            fi

            MODULES_OPTION=''
            if [[ ! -z '<<parameters.module>>' ]]; then
              MODULES_OPTION='-pl <<parameters.module>>'
            fi
            mvn <<parameters.phase>> --batch-mode \
                    -f <<parameters.pom_file>> \
                    $CHECKSTYLE_OPTION \
                    $SKIPTESTS_OPTION \
                    -Dddp.cacheDir="$ddp_cache_dir" \
                    -Ditext.license=output-config/itextkey.xml \
                    $CONFIG_FILE_OPTION  \
                    -Dmaven.repo.local=<< parameters.m2_repo >> <<parameters.additional_options>> \
                    $MODULES_OPTION
          background: <<parameters.background>>
      - when:
          condition: << parameters.save_m2_cache >>
          steps:
            - save_cache:
                key: *m2_cache_key
                paths:
                  - << parameters.root_path >>/.m2
      - run:
          name: Copy test results
          command: |
            mkdir -p ~/test-results/junit/
            find . -type f -regex ".*/target/surefire-reports/.*xml" -exec cp {} ~/test-results/junit/ \;
          when: always
      - store_test_results:
          path: ~/test-results
      - when:
          condition: << parameters.coverage_report >>
          steps:
            - run:
                name: Generate coverage report
                command: |
                  mvn jacoco:report \
                    -Dddp.cacheDir="$ddp_cache_dir" \
                    -Dmaven.repo.local=<< parameters.m2_repo >> <<parameters.additional_options>>
      - when:
          condition: << parameters.sonar_scan >>
          steps:
            - run:
                name: Run sonar scan
                command: |
                    if [[ ! -z '<<parameters.module>>' ]]; then
                      cd <<parameters.module>>
                    fi
                    mvn sonar:sonar  \
                      -Dddp.cacheDir="$ddp_cache_dir" \
                      -Dmaven.repo.local=<< parameters.m2_repo >>
                    if [[ ! -z '<<parameters.module>>' ]]; then
                      cd ..
                    fi
      - when:
          condition:
            and:
              - << parameters.sonar_scan >>
              - << parameters.sonar_additional_module >>
          steps:
            - run:
                name: 'Run sonar scan on <<parameters.sonar_additional_module>>'
                command: |
                  cd <<parameters.sonar_additional_module>>
                  mvn sonar:sonar  \
                    -Dddp.cacheDir="$ddp_cache_dir" \
                    -Dmaven.repo.local=<< parameters.m2_repo >>
                  cd ..

  wait_for_server:
    description: Wait for a server to respond for specific period of time
    parameters:
      server_address:
        type: string
        default: '127.0.0.1'
      port:
        type: integer
      timeout:
        type: integer
        default: 60
    steps:
      - run:
          name: Waiting for server to start
          command: |
            for i in `seq 1 << parameters.timeout >>`;
            do
              nc -z << parameters.server_address >> << parameters.port >> && echo Success && exit 0
              echo -n .
              sleep 1
            done
            echo Failed waiting for << parameters.server_address >> << parameters.port >> to start && exit 1

  start-ddp-test-server:
    description: Run test server that applies liquibase and load test data
    steps:
      - run-maven-with-pepper-options:
          module: dss-core
          phase: exec:java
          additional_options: '-Dexec.mainClass=org.broadinstitute.ddp.route.IntegrationTestSuite -Dexec.classpathScope=test'
          background: true
      - wait_for_server:
          port: 5556
          timeout: 60

  compile-all-jars:
    description: Compile and run checkstyle on all jars with code
    parameters:
      m2_repo:
        type: string
        default: *m2_repo_path
      repo_path:
        type: string
        default: *repo_path
      restore_m2_cache:
        type: boolean
        default: false
    steps:
      - when:
          condition: << parameters.restore_m2_cache >>
          steps:
            - restore_cache: *m2_cache_keys
      - run:
          name: Compile and run checkstyle on all jars
          command: |
            mvn install --batch-mode -DskipTests -Dmaven.repo.local=<< parameters.m2_repo >> -pl dsm-core,dss-core,studybuilder-cli -am -T 1.5C

  restore-ddp-cache:
    description: Restore ddp cache
    parameters:
      ddp_cache_md5_file:
        type: string
        default: *ddp_cache_md5_file
    steps:
      - run:
          name: Check CircleToken API Credentials
          command: |
            token_status_code=$(curl -s -o /dev/null -w "%{http_code}" "https://circleci.com/api/v2/me" --header "Circle-Token:$CIRCLE_TOKEN")
            if [[ $token_status_code != "200" ]]; then
              echo "The CircleCI *personal* API Token is no longer valid.  Please update the value of the environment variable CIRCLE_TOKEN."
              echo "Stopping build"
              exit 1
            fi
      - run:
          name: Download ddp-cache-md5 artifact
          command: |
            ddp_cache_md5='<<parameters.ddp_cache_md5_file>>'
            latest_artifact_url="https://circleci.com/api/v1.1/project/github/broadinstitute/ddp-study-server/latest/artifacts?circle-token=$CIRCLE_TOKEN"
            md5_artifact_url=$(curl -sL "$latest_artifact_url" | jq -r '.[] | select(.node_index == 0) | select(.path == "ddp-cache-md5.txt") | .url')
            if [[ -n "$md5_artifact_url" ]]; then
              echo "Downloading artifact file [$md5_artifact_url] to file [$ddp_cache_md5]"
              curl -sL "$md5_artifact_url?circle-token=$CIRCLE_TOKEN" -o "$ddp_cache_md5"
            else
              echo "No artifact file found, creating empty file [$ddp_cache_md5]"
              touch "$ddp_cache_md5"
            fi
      - restore_cache:
          keys:
            - ddp-cache-{{ checksum "<<parameters.ddp_cache_md5_file>>" }}
            - ddp-cache-

  save-ddp-cache:
    description: Save ddp cache
    parameters:
      ddp_cache_dir:
        type: string
        default: *ddp_cache_dir
      ddp_cache_md5_file:
        type: string
        default: *ddp_cache_md5_file
    steps:
      - run:
          name: Compute ddp-cache-md5
          command: |
            ddp_cache_dir='<<parameters.ddp_cache_dir>>'
            ddp_cache_md5='<<parameters.ddp_cache_md5_file>>'
            echo -n "" > "$ddp_cache_md5"
            for cached_file in $(ls "$ddp_cache_dir" | sort); do
              md5sum "$ddp_cache_dir/$cached_file" >> "$ddp_cache_md5"
            done
            echo "Contents of [$ddp_cache_md5]:"
            cat "$ddp_cache_md5"
      - save_cache:
          key: ddp-cache-{{ checksum "<<parameters.ddp_cache_md5_file>>" }}
          paths:
            - <<parameters.ddp_cache_dir>>
      - store_artifacts:
          path: <<parameters.ddp_cache_md5_file>>
          destination: ddp-cache-md5.txt

  match-file-patterns-or-halt:
    description: Halt execution if matching file patter has been modified (currently not used!)
    parameters:
      file_patterns:
        type: string
        default: "pepper-apis"
    steps:
      - run:
          name: Check git changes and stop the job early if certain files did not change
          command: |
            file_patterns='<<parameters.file_patterns>>'
            file_patterns+=' .circleci/config.yml'
            echo "Checking file patterns: $file_patterns"
            matched=false
            for pattern in $(echo "$file_patterns"); do
              if git diff --name-only origin/develop "$CIRCLE_BRANCH" | grep -e "$pattern" > /dev/null; then
                echo "Matched pattern: $pattern"
                matched=true
                break
              fi
            done
            if [[ "$matched" == 'false' ]]; then
              echo "No file patterns matched, skipping job"
              circleci step halt
            fi

jobs:
  build-api-docs-job:
    executor:
      name: build-deploy-executor
    working_directory: *repo_path
    parameters:
      spec_dir:
        type: string
        default: *api-spec-path
    steps:
      - run: echo "Doing build-api-docs-job << pipeline.parameters.api-docs >>"
      - when:
          condition: << pipeline.parameters.api-docs >>
          steps:
            - checkout
            - run:
                name: Build docs
                command: |
                  cd << parameters.spec_dir >>
                  ./build.sh documentation

  dsm-compile-and-run-tests-job:
    executor:
      name: test-executor
    working_directory: *pepper_apis_path
    parameters:
      pepper_apis_path:
        type: string
        default: *pepper_apis_path
    steps:
      - run: echo 'Doing dsm-compile-and-run-tests-job << pipeline.parameters.dsm >>'
      - when:
          condition: << pipeline.parameters.dsm >>
          steps:
            - run:
                name: Remove directory << parameters.pepper_apis_path >> for checkout of files
                command: |
                  rmdir << parameters.pepper_apis_path >>
            - checkout:
                path: *repo_path
            - setup-shared-env
            - run-maven-with-pepper-options:
                module: dsm-core
                phase: install
                skip_tests: true
                skip_checkstyle: false
                config_file_path: ''
                additional_options: -am
                restore_m2_cache: true
                save_m2_cache: false
            - render-configs
            - create-test-dbs
            - restore-ddp-cache
            - run-maven-with-pepper-options:
                module: dsm-core
                phase: test
                skip_tests: false
                skip_checkstyle: true
                additional_options: -PDefaultBuild,coverage -Ddsm.test.excludes='${dsm.test.ci.excludes}'
                restore_m2_cache: false
                save_m2_cache: false    #REMOVE WHEN DONE
                coverage_report: true
                sonar_scan: true
                sonar_additional_module: 'ddp-common'
            - save-ddp-cache
            - persist_to_workspace:
                root: *root_path
                paths:
                  - repo

  dss-compile-and-run-test-suite-job:
    description: Job that runs DSS tests that cannot be done in parallel
    executor:
      name: test-executor
    working_directory: *pepper_apis_path
    parameters:
      allow_skip_job:
        type: boolean
        default: false
      pepper_apis_path:
        type: string
        default: *pepper_apis_path
    steps:
      - run: echo "Doing dss-compile-and-run-test-suite-job << pipeline.parameters.dss >>"
      - when:
          condition: << pipeline.parameters.dss >>
          steps:
            - run:
                name: Remove directory << parameters.pepper_apis_path >> to allow checkout of code
                command: |
                  rmdir << parameters.pepper_apis_path >>
            - checkout:
                path: *repo_path
            - setup-shared-env
            - compile-all-jars:
                restore_m2_cache: true
            - render-configs
            - create-test-dbs
            - restore-ddp-cache
            - run-maven-with-pepper-options:
                module: dss-core
                phase: test
                skip_tests: false
                skip_checkstyle: true
                additional_options: '-PDefaultBuild,coverage -Dtest=ServerInSameProcessIntegrationTestSuite'
                restore_m2_cache: false
                coverage_report: true
                sonar_scan: true
            - save-ddp-cache

  dss-parallel-compile-and-test-job:
    description: Job that runs DSS tests that CAN be done in parallel
    executor:
      name: test-executor
    working_directory: *pepper_apis_path
    parallelism: <<parameters.parallelism>>
    parameters:
      parallelism:
        type: integer
        default: 2
      pepper_apis_path:
        type: string
        default: *pepper_apis_path
    steps:
      - run: echo "Doing dss-parallel-compile-and-test-job << pipeline.parameters.dss >>"
      - when:
          condition: << pipeline.parameters.dss >>
          steps:
            - run:
                name: Remove directory << parameters.pepper_apis_path >> to allow checkout of code
                command: |
                  rmdir << parameters.pepper_apis_path >>
            - checkout:
                path: *repo_path
            - setup-shared-env
            - render-configs
            - run-maven-with-pepper-options: # Build stuff first so we can setup everything
                phase: install
                module: dss-core
                restore_m2_cache: true
                skip_checkstyle: true
                skip_tests: true
                additional_options: -am
            - create-test-dbs
            - start-ddp-test-server # starts DDP server. And execute Liquibase DB population
            - compute-parallel-test-split
            - restore-ddp-cache
            - run-maven-with-pepper-options: # Running the tests. Only those assigned to this parallel job!
                phase: test
                skip_tests: false
                module: dss-core
                additional_options: '-PCircleciParallelBuild,coverage -Dsurefire.excludesFile=$IGNORE_CLASS_LIST_PATH -DcachingDisabled=true'
                save_m2_cache: true
                coverage_report: true
                sonar_scan: true
            - save-ddp-cache
            - run:
                name: 'Check node index to save workspace only once'
                command: |
                  if [[ "$CIRCLE_NODE_INDEX" -ne 0 ]]; then
                    echo "Skip persist workspace on this node";
                    circleci step halt;
                  fi
            - persist_to_workspace:
                root: *root_path
                paths:
                  - repo

  dss-store-jar-job:
    description: Build DSS specific jars and store them in buckets
    executor:
      name: build-deploy-executor
    working_directory: *pepper_apis_path
    steps:
      - attach_workspace:
          at: *root_path
      - setup-shared-env
      - build-jar:
          module: dss-server
      - store-jar:
          module: dss-server
          jar_base_name: DataDonationPlatform
      - build-jar:
          module: housekeeping
      - store-jar:
          module: housekeeping
          jar_base_name: Housekeeping

  dsm-store-jar-job:
    description: Build DSM jar and store it in bucket
    executor:
      name: build-deploy-executor
    working_directory: *pepper_apis_path
    steps:
      - attach_workspace:
          at: *root_path
      - setup-shared-env
      - build-jar:
          module: dsm-server
      - store-jar:
          module: dsm-server
          jar_base_name: DSMServer

  dss-deploy-jar-from-workspace-job:
    executor:
      name: build-deploy-executor
    working_directory: *pepper_apis_path
    steps:
      - attach_workspace:
          at: *root_path
      - setup-shared-env
      # Deploy Housekeeping first so hopefully liquibase migrations
      # are run before DDP boots up.
      - build-jar:
          module: housekeeping
      - deploy-jar:
          jar_base_name: Housekeeping
          application: housekeeping
          module: housekeeping
          deploy_config_file_dir: ../output-config
      - build-jar:
          module: dss-server
      - deploy-jar:
          jar_base_name: DataDonationPlatform
          module: dss-server
          deploy_config_file_dir: ../output-config

  deploy-dsm-from-workspace-job:
    description: Deploy DSM from workspace created in another job that contains build.
    executor:
      name: build-deploy-executor
    working_directory: *pepper_apis_path
    steps:
      - attach_workspace:
          at: *root_path
      - setup-shared-env
      - build-jar:
          module: dsm-server
      - deploy-dsm-jar

  deploy-dss-stored-jar-job:
    executor:
      name: build-deploy-executor
    working_directory: *pepper_apis_path
    steps:
      - checkout:
          path: *repo_path
      - setup-shared-env
      # Deploy Housekeeping first so hopefully liquibase migrations
      # run before DDP boots up.
      - retrieve-jar:
          jar_base_name: Housekeeping
          module: housekeeping
      - deploy-jar:
          jar_base_name: Housekeeping
          module: housekeeping
          deploy_config_file_dir: ../output-config
      - retrieve-jar:
          jar_base_name: DataDonationPlatform
          module: dss-server
      - deploy-jar:
          jar_base_name: DataDonationPlatform
          module: dss-server
          deploy_config_file_dir: ../output-config

  deploy-dsm-stored-jar-job:
    executor:
      name: build-deploy-executor
    working_directory: *pepper_apis_path
    steps:
      - checkout:
          path: *repo_path
      - setup-shared-env
      - retrieve-jar:
          jar_base_name: DSMServer
          module: dsm-server
      - deploy-dsm-jar

  build-deploy-docs-job:
    executor:
      name: build-deploy-executor
    working_directory: *api-spec-path
    parameters:
      pepper_apis_path:
        type: string
        default: *pepper_apis_path
    steps:
      - run:
          name: Remove recursively << parameters.pepper_apis_path >>
          command: |
            rm -r << parameters.pepper_apis_path >>
      - checkout:
          path: *repo_path
      - run:
          name: Build docs
          command: ./build.sh documentation
      - setup-shared-env
      - set-deployment-env
      - auth-gcp-service-account
      - run:
          name: Deploy docs website
          command: |
            set -u
            gcloud app deploy --version="${SHORT_GIT_SHA}" --stop-previous-version --project "broad-ddp-${ENVIRONMENT}" deploy/app.yaml
      - delete-old-service-versions:
          deploy_dir: deploy

parameters:
  on_demand:
    type: boolean
    default: false

  project:
    type: enum
    enum: ["dss", "dsm","api-docs", "nothing"]
    default: "dss"

  action:
    type: enum
    enum: ["build-test", "build-test-deploy", "build-test-store", "retrieve-deploy", "nothing"]
    default: "nothing"

  dss:
    type: boolean
    default: false

  test_parallelism:
    type: integer
    default: 1

  api-docs:
    type: boolean
    default: false

  dsm:
    type: boolean
    default: false


workflows:
  version: 2

  # Triggered from a local script to test PR changes
  combined-build-test-workflow:
    when:
      equal: ["build-test", << pipeline.parameters.action >>]
    jobs:
      - dss-compile-and-run-test-suite-job
      - dss-parallel-compile-and-test-job:
          parallelism: << pipeline.parameters.test_parallelism >> # the caller of this workflow will tell us the parallelism
      - dsm-compile-and-run-tests-job
      - build-api-docs-job

  # Build and deploy API docs
  api-docs-build-test-deploy-workflow:
    when:
      and:
        - equal: ["build-test-deploy", << pipeline.parameters.action >>]
        - << pipeline.parameters.api-docs >>
    jobs:
      - build-deploy-docs-job

  # Build , run all tests, and immediately deploy DSS. Currently used in develop branch and dev environment
  dss-build-test-deploy-workflow:
    when:
      and:
        - equal: ["build-test-deploy", << pipeline.parameters.action >>]
        - << pipeline.parameters.dss >>
    jobs:
      - dss-compile-and-run-test-suite-job
      - dss-parallel-compile-and-test-job:
          parallelism: *test_parallelism
      - dss-deploy-jar-from-workspace-job:
          requires:
            - dss-parallel-compile-and-test-job
            - dss-compile-and-run-test-suite-job

  # Run DSM tests
  dsm-build-test-deploy-workflow:
    when:
      and:
        - equal: ["build-test-deploy", << pipeline.parameters.action >>]
        - << pipeline.parameters.dsm >>
    jobs:
      - dsm-compile-and-run-tests-job
      - deploy-dsm-from-workspace-job:
          requires:
            - dsm-compile-and-run-tests-job

  # Build and tests DSS applications and then store the corresponding jars
  dss-build-test-store-workflow:
    when:
      and:
        - equal: ["build-test-store", << pipeline.parameters.action >>]
        - << pipeline.parameters.dss >>
    jobs:
      - dss-compile-and-run-test-suite-job #running tests before we store!
      - dss-parallel-compile-and-test-job:
          parallelism: *test_parallelism
      - dss-store-jar-job:
          requires:
            - dss-compile-and-run-test-suite-job
            - dss-parallel-compile-and-test-job

  # Deploy DSS applications from previously built jars in buckets
  dss-deploy-workflow:
    when:
      and:
        - equal: ["retrieve-deploy", << pipeline.parameters.action >>]
        - << pipeline.parameters.dss >>
    jobs:
      - deploy-dss-stored-jar-job
      - build-deploy-docs-job

  # DSM build and test and then store the jar in a bucket for later deployment
  dsm-build-test-store-workflow:
    when:
      and:
        - equal: ["build-test-store", << pipeline.parameters.action >>]
        - << pipeline.parameters.dsm >>
    jobs:
      - dsm-compile-and-run-tests-job
      - dsm-store-jar-job:
          requires:
            - dsm-compile-and-run-tests-job

  # Retrieve the DSM jar from bucket and deploy it
  dsm-deploy-workflow:
    when:
      and:
        - equal: ["retrieve-deploy", << pipeline.parameters.action >>]
        - << pipeline.parameters.dsm >>
    jobs:
      - deploy-dsm-stored-jar-job
